{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Representation of Text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "import umap.umap_ as umap\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test with Real Data (181 data)\n",
    "\n",
    "### 1.1. Loading Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Loading Fast Check Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {}\n",
    "\n",
    "with open(\"../image_model/json_data_fact_checking.json\", 'r', encoding='utf-8') as file:\n",
    "    json_data = json.load(file)  \n",
    "fact_checking_text = [fact[\"text\"] for fact in json_data[\"pages\"]]\n",
    "\n",
    "with open(\"../image_model/json_data_fast_check_1_fixed.json\", 'r', encoding='utf-8') as file:\n",
    "    json_data = json.load(file)  \n",
    "text_1st_process = [fact[\"text\"] for fact in json_data[\"pages\"]]\n",
    "\n",
    "with open(\"../image_model/json_data_fast_check_2_fixed.json\", 'r', encoding='utf-8') as file:\n",
    "    json_data = json.load(file)  \n",
    "text_2nd_process = [fact[\"text\"] for fact in json_data[\"pages\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Modeling with BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dccuchile/bert-base-spanish-wwm-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, truncation=False)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "def get_embeddings(texts):\n",
    "    encodings = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_1st = get_embeddings(text_1st_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_2st = get_embeddings(text_2nd_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_fact_checking = get_embeddings(fact_checking_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embeddings_1st, '../embeddings/1st_text_embeddings.pt')\n",
    "torch.save(embeddings_2st, '../embeddings/2nd_text_embeddings.pt')\n",
    "torch.save(embeddings_fact_checking, '../embeddings/fact_checking_text_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_1st = torch.load('../embeddings/1st_text_embeddings.pt')\n",
    "embeddings_2st = torch.load('../embeddings/2nd_text_embeddings.pt')\n",
    "embeddings_fact_checking = torch.load('../embeddings/fact_checking_text_embeddings.pt')\n",
    "embeddings = np.concatenate([embeddings_1st, embeddings_2st, embeddings_fact_checking])\n",
    "\n",
    "print(embeddings_1st.shape)\n",
    "print(embeddings_2st.shape)\n",
    "print(embeddings_fact_checking.shape)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Modeling with BERT - t-SNE 2D Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=1, random_state=42)\n",
    "embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=6, min_samples=3, cluster_selection_epsilon=10)\n",
    "cluster_labels = clusterer.fit_predict(embeddings_2d)\n",
    "\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=cluster_labels, cmap='viridis', s=10)\n",
    "plt.title('Results using t-SNE and HDBSCAN')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(label='Cluster Label')\n",
    "plt.show()\n",
    "\n",
    "distances = pairwise_distances(embeddings_2d, metric='euclidean')\n",
    "average_distance = np.mean(distances)\n",
    "min_distance = np.min(distances[distances > 0])\n",
    "max_distance = np.max(distances)\n",
    "\n",
    "print(f\"Distancia promedio: {average_distance}\")\n",
    "print(f\"Distancia mínima: {min_distance}\")\n",
    "print(f\"Distancia máxima: {max_distance}\")\n",
    "\n",
    "score = silhouette_score(embeddings_2d, cluster_labels)\n",
    "print(f\"Silhouette Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'fact_checking_data': 'red', 'fast_check_1st': 'blue', 'fast_check_2nd': 'green'}\n",
    "\n",
    "cluster_to_print = -1\n",
    "facts_selected = []\n",
    "facts_labels = []\n",
    "\n",
    "for index, fact in enumerate(embeddings_2d):\n",
    "    if cluster_labels[index] == cluster_to_print:\n",
    "        facts_selected.append(embeddings_2d[index].tolist())\n",
    "        facts_labels.append(index)\n",
    "\n",
    "plt.scatter([fact[0] for fact in facts_selected], [fact[1] for fact in facts_selected], s=10)\n",
    "for x, y, etiqueta in zip([fact[0] for fact in facts_selected], [fact[1] for fact in facts_selected], facts_labels):\n",
    "    plt.annotate(etiqueta, (x, y), textcoords=\"offset points\", xytext=(0, 3), ha='center')\n",
    "\n",
    "legend_labels = [mpatches.Patch(color=color, label=label) for label, color in colors.items()]\n",
    "plt.legend(handles=legend_labels, title=\"Sites\", fontsize=8)\n",
    "plt.title(f'Focusing on Cluster {cluster_to_print}')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Modeling with BERT - UMAP 2D Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = umap.UMAP(n_components=2, random_state=10, n_neighbors=3, min_dist=0.0, n_jobs=1, init='random')\n",
    "embeddings_2d = umap_model.fit_transform(embeddings)\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=3, cluster_selection_epsilon=0.5)\n",
    "cluster_labels = clusterer.fit_predict(embeddings_2d)\n",
    "\n",
    "# Visualizar los resultados\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=cluster_labels, s=10)\n",
    "plt.title('Results using UMAP and HDBSCAN')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(label='Cluster Label')\n",
    "plt.show()\n",
    "\n",
    "distances = pairwise_distances(embeddings_2d, metric='euclidean')\n",
    "# Calcular la distancia promedio entre todos los puntos en el espacio 2D\n",
    "average_distance = np.mean(distances)\n",
    "# Calcular la distancia mínima entre puntos\n",
    "min_distance = np.min(distances[distances > 0])  # Excluyendo la diagonal (distancia de un punto consigo mismo)\n",
    "# Calcular la distancia máxima entre puntos\n",
    "max_distance = np.max(distances)\n",
    "print(f\"Distancia promedio: {average_distance}\")\n",
    "print(f\"Distancia mínima: {min_distance}\")\n",
    "print(f\"Distancia máxima: {max_distance}\")\n",
    "\n",
    "# Evaluar la calidad del clustering\n",
    "score = silhouette_score(embeddings_2d, cluster_labels)\n",
    "print(f\"Silhouette Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors = {'fact_checking_data': 'red', 'fast_check_1st': 'blue', 'fast_check_2nd': 'green'}\n",
    "\n",
    "cluster_to_print = 1\n",
    "facts_selected = []\n",
    "facts_labels = []\n",
    "\n",
    "for index, fact in enumerate(embeddings_2d):\n",
    "    if cluster_labels[index] == cluster_to_print:\n",
    "        facts_selected.append(embeddings_2d[index].tolist())\n",
    "        facts_labels.append(index)\n",
    "\n",
    "plt.scatter([fact[0] for fact in facts_selected], [fact[1] for fact in facts_selected], s=10)\n",
    "\n",
    "for x, y, etiqueta in zip([fact[0] for fact in facts_selected], [fact[1] for fact in facts_selected], facts_labels):\n",
    "    plt.annotate(etiqueta, (x, y), textcoords=\"offset points\", xytext=(0, 3), ha='center')\n",
    "\n",
    "legend_labels = [mpatches.Patch(color=color, label=label) for label, color in colors.items()]\n",
    "plt.legend(handles=legend_labels, title=\"Sites\", fontsize=8)\n",
    "\n",
    "plt.title(f'Focusing on Cluster {cluster_to_print}')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
